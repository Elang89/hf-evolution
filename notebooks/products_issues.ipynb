{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28dd8fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from pprint import pprint\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import ne_chunk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sqlalchemy import create_engine\n",
    "from scipy.stats import describe\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "from scripts.issues_utils import merge_issues_comments\n",
    "from scripts.stats_utils import calculate_four_moments\n",
    "from scripts.lda_utils import (\n",
    "    clean_text, \n",
    "    calculate_perplexities, \n",
    "    extract_dominant_topics, \n",
    "    create_cat_dataframe,\n",
    "    perform_grid_search,\n",
    "    generate_wordcloud\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed0a82ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/elang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/elang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/elang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/elang/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")    \n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c2c07c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = create_engine(\"postgresql://root:password@localhost:5435/hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0bbc66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_issues_software = pd.read_sql_query(\"\"\"\n",
    "    SELECT * \n",
    "    FROM issues AS i\n",
    "    INNER JOIN github_repositories AS g ON\n",
    "        i.github_repository_id = g.id\n",
    "    AND \n",
    "        g.repository_type = 1\n",
    "\"\"\", con=conn)\n",
    "\n",
    "df_issues_hf = pd.read_sql_query(\"\"\"\n",
    "    SELECT * \n",
    "    FROM issues AS i\n",
    "    INNER JOIN github_repositories AS g ON\n",
    "        i.github_repository_id = g.id\n",
    "    wHERE \n",
    "        g.repository_type = 2\n",
    "\"\"\", con=conn)\n",
    "\n",
    "df_issues_ml = pd.read_sql_query(\"\"\"\n",
    "    SELECT * \n",
    "    FROM issues AS i\n",
    "    INNER JOIN github_repositories AS g ON\n",
    "        i.github_repository_id = g.id\n",
    "    WHERE \n",
    "        g.repository_type = 3\n",
    "\"\"\", con=conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e202ebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments_software = pd.read_sql_query(\"\"\"\n",
    "    SELECT * \n",
    "    FROM issue_comments AS c\n",
    "    INNER JOIN issues AS i ON\n",
    "        i.id = c.issue_id\n",
    "    INNER JOIN github_repositories AS g ON\n",
    "        i.github_repository_id = g.id\n",
    "    WHERE \n",
    "        g.repository_type = 1\n",
    "\"\"\", con=conn)\n",
    "\n",
    "df_comments_hf = pd.read_sql_query(\"\"\"\n",
    "    SELECT * \n",
    "    FROM issue_comments AS c\n",
    "    INNER JOIN issues AS i ON\n",
    "        i.id = c.issue_id\n",
    "    INNER JOIN github_repositories AS g ON\n",
    "        i.github_repository_id = g.id\n",
    "    WHERE \n",
    "        g.repository_type = 2\n",
    "\"\"\", con=conn)\n",
    "\n",
    "df_comments_ml = pd.read_sql_query(\"\"\"\n",
    "    SELECT * \n",
    "    FROM issue_comments AS c\n",
    "    INNER JOIN issues AS i ON\n",
    "        i.id = c.issue_id\n",
    "    INNER JOIN github_repositories AS g ON\n",
    "        i.github_repository_id = g.id\n",
    "    WHERE \n",
    "        g.repository_type = 3\n",
    "\"\"\", con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4a3c818",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_software = merge_issues_comments(df_issues_software, df_comments_software)\n",
    "docs_hf = merge_issues_comments(df_issues_hf, df_comments_hf)\n",
    "docs_ml = merge_issues_comments(df_issues_ml, df_comments_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0cef0b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_software = TfidfVectorizer(stop_words=stop_words, max_features=1000)\n",
    "vect_hf = TfidfVectorizer(stop_words=stop_words, max_features=1000)\n",
    "vect_ml = TfidfVectorizer(stop_words=stop_words, max_features=1000)\n",
    "\n",
    "vect_text_software = vect_software.fit_transform(docs_software[\"document\"])\n",
    "vect_text_hf = vect_hf.fit_transform(docs_hf[\"document\"])\n",
    "vect_text_ml = vect_ml.fit_transform(docs_ml[\"document\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fd67e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_software = vect_software.get_feature_names_out()\n",
    "vocab_hf = vect_hf.get_feature_names_out()\n",
    "vocab_ml = vect_ml.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809a4111",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {\"n_components\": [2, 3, 4, 5, 10, 15, 20], \"learning_decay\": [0.5, 0.7, 0.9]}\n",
    "\n",
    "model_software = perform_grid_search(search_params, vect_text_software)\n",
    "model_hf = perform_grid_search(search_params, vect_text_hf)\n",
    "model_ml = perform_grid_search(search_params, vect_text_ml)\n",
    "\n",
    "print(f\"Best Parameters Software: {model_software.best_param_}\")\n",
    "print(f\"Best Log Likelihood Software: {model_hf.best_score_}\")\n",
    "\n",
    "print(f\"Best Parameters HF: {model_hf.best_param_}\")\n",
    "print(f\"Best Log Likelihood Software: {model_hf.best_score_}\")\n",
    "\n",
    "print(f\"Best Parameters ML: {model_ml.best_param_}\")\n",
    "print(f\"Best Log Likelihood ML: {model_ml.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10113770",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_software = calculate_perplexities(search_params, vect_text_software)\n",
    "models_hf = calculate_perplexities(search_params, vect_text_hf)\n",
    "models_ml = calculate_perplexities(search_params, vect_text_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75322305",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities_software = [item[\"perplexity\"] for item in models_software]\n",
    "perplexities_hf = [item[\"perplexity\"] for item in models_hf]\n",
    "perplexities_ml = [item[\"perplexity\"] for item in models_ml]\n",
    "\n",
    "results_software = pd.DataFrame(model_software.cv_results_)\n",
    "results_hf = pd.DataFrame(model_hf.cv_results_)\n",
    "results_ml = pd.DataFrame(model_ml.cv_results_)\n",
    "\n",
    "results_software[\"perplexity\"] = perplexities_software\n",
    "results_hf[\"perplexity\"] = perplexities_hf\n",
    "results_ml[\"perplexity\"] = perplexities_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239cf715",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_palette = sns.color_palette(\"tab10\", 3)\n",
    "fontsize = 16\n",
    "pad = 20\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=3, figsize=(18, 8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
